{
  "hash": "d7c5a213d69a16df7297265a813cf7ab",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Review:\"\nsubtitle: \"More Probability Theory\"\nformat:\n  revealjs:\n    include-in-header: \"math_commands.html\"\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  \nfilters: \n  - reveal-auto-agenda\n\neditor: source\n---\n\n# Moment Generating Functions\n\n## Moments\n\nThe $k$th moment is defined as the expectation of the random variable, raised to the $k$th power, defined as $E(X^k)$.\n\n## Moment Generating Functions\n\nThe moment generating functions is used to obtain the $k$th moment. The mgf is defined as\n\n$$\nm(t) = E(e^{tX})\n$$\n\nThe $k$th moment can be obtained by taking the $k$th derivative of the mgf, with respect to $t$, and setting $t$ equal to 0:\n\n$$\nE(X^k)=\\frac{d^km(t)}{dt}\\Bigg|_{t=0}\n$$\n\n# Characteristic Functions\n\n## Characteristic Functions\n\n$$\n\\phi(t) = E\\left(e^{itX}\\right) = E\\left\\{\\cos(tX)\\right\\}  + iE\\left\\{\\sin(tX)\\right\\}\n$$\n\n# Poisson Distribution\n\n## MGF\n\n## Expected Value\n\n## Variance\n\n## Variance\n\n# Binomial Distribution\n\n## MGF\n\n# Uniform Distribution\n\n## MGF\n\n# Normal Distribution\n\n## MGF\n\n# MGF Properties\n\n## Linearity\n\nLet $X$ follow a distribution $f$, with the an MGF $M_X(t)$, the MGF of $Y=aX+b$ is given as\n\n$$\nM_Y(t) = e^{tb}M_X(at)\n$$\n\n## Derivation\n\n## Linearity\n\nLet $X$ and $Y$ be two random variables with MGFs $M_X(t)$ and $M_Y(t)$, respectively, and are independent. The MGF of $U=X-Y$\n\n$$\nM_U(t) = M_X(t)M_Y(-t)\n$$\n\n## Derivation\n\n## Uniqueness\n\nLet $X$ and $Y$ have the following distributions $F_X(x)$ and $F_Y(y)$ and MGFs $M_X(t)$ and $M_Y(t)$, respectively. $X$ and $Y$ have the same distribution $F_X(x)=F_Y(y)$ if and only if $M_X(t)=M_Y(t)$.\n\n## Uniqueness\n\nLet $X_1,\\cdots, X_n$ be independent random variables, where $X_i\\sim N(\\mu_i, \\sigma^2_i)$, with $M_{X_i}(t)=\\exp\\{\\mu_i t+\\sigma^2_it^2/2\\}$ for $i=1,\\cdots, n$. Find the MGF of $Y=a_1X_1+\\cdots+a_nX_n$, where $a_1, \\cdots, a_n$ are constants.\n\n\n\n# Function of Random Variables\n\n## Function of Random Variables\n\n# Obtaining the PDFs\n\n## Using the Distribution Function\n\nLet there be a random variable $X$ with a known distribution function $F_X(x)$, the density function for the random variable $Y=g(X)$ can be found with the following steps\n\n::: fragment\n::: nonincremental\n1.  Find the region of $Y$ in the space of $X$, find $g^{-1}(y)$\n2.  Find the region of $Y\\le y$\n3.  Find $F_Y(y)=P(Y\\le y)$ using the probability density function of $X$ over region $Y\\le y$\n4.  Find $f_Y(y)$ by differentiating $F_Y(y)$\n:::\n:::\n\n## Example 1\n\nLet $X$ have the following probability density function:\n\n$$\nf_X(x)=\\left\\{\\begin{array}{cc}\n2x & 0\\le x \\le 1 \\\\\n0 & \\mathrm{otherwise}\n\\end{array}\n\\right.\n$$\n\nFind the probability density function of $Y=3X-1$?\n\n## Using the PDF\n\nLet there be a random variable $X$ with a known distribution function $F_X(x)$, if the random variable $Y=g(X)$ is either increasing or decreasing, than the probability density function can be found as\n\n$$\nf_Y(y) = f_X\\{g^{-1}(y)\\}\\left|\\frac{dg^{-1}(y)}{dy}\\right|\n$$\n\n## Example 2\n\nLet $X$ have the following probability density function:\n\n$$\nf_X(x)=\\left\\{\\begin{array}{cc}\n\\frac{3}{2}x^2 + x & 0\\le y \\le 1 \\\\\n0 & \\mathrm{otherwise}\n\\end{array}\n\\right.\n$$\n\nFind the probability density function of $Y=5-(X/2)$?\n\n## Using the MGF\n\nUsing the uniqueness property of Moment Generating Functions, for a random variable $X$ with a known distribution function $F_X(x)$ and random variable $Y=g(X)$, the distribution of $Y$ can be found by:\n\n::: nonincremental\n1.  Find the moment generating function of $Y$, $M_Y(t)$.\n2.  Compare $M_Y(t)$, with known moment generating functions. If $M_Y(t)=M_V(t)$, for all values $t$, them $Y$ and $V$ have identical distributions.\n:::\n\n## Example 3\n\nLet $X$ follow a normal distribution with mean $\\mu$ and variance $\\sigma^2$. Find the distribution of $Z=\\frac{X-\\mu}{\\sigma}$.\n\n## Example 4\n\nLet $Z$ follow a standard normal distribution with mean $0$ and variance $1$. Find the distribution of $Y=Z^2$\n",
    "supporting": [
      "2b_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}